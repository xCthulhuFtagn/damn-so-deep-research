version: "3.9"

services:
  backend:
    build:
      context: ..
      dockerfile: infrastructure/Dockerfile.backend
    ports:
      - "8000:8000"
    env_file:
      - ../.env
    environment:
      - DATABASE_PATH=/app/db/${DB_NAME:-app.db}
      - LANGGRAPH_CHECKPOINT_PATH=/app/db/langgraph.db
      - SEARXNG_URL=http://searxng:8080
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-http://vllm:8001/v1}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-EMPTY}
      - OPENAI_MODEL=${OPENAI_MODEL:-openai/gpt-oss-20b}
      - AUTH_SECRET_KEY=${AUTH_SECRET_KEY:-your-secret-key-change-in-production}
      - FIRECRAWL_API_KEY=${FIRECRAWL_API_KEY}
    volumes:
      - ../db:/app/db
      - ../.env:/app/.env:ro
    depends_on:
      - searxng
      - vllm
    networks:
      - research-net
    restart: unless-stopped

  frontend:
    build:
      context: ..
      dockerfile: infrastructure/Dockerfile.frontend
    ports:
      - "5173:80"
    environment:
      - VITE_API_URL=http://localhost:8000
      - VITE_WS_URL=ws://localhost:8000
    depends_on:
      - backend
    networks:
      - research-net
    restart: unless-stopped

  searxng:
    image: searxng/searxng:latest
    ports:
      - "8080:8080"
    volumes:
      - ./searxng/settings.yml:/etc/searxng/settings.yml:ro
      - ./searxng/limiter.toml:/etc/searxng/limiter.toml:ro
    environment:
      - SEARXNG_BASE_URL=http://localhost:8080/
    networks:
      - research-net
    restart: unless-stopped

  vllm:
    image: vllm/vllm-openai:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    env_file:
      - ../.env
    command: >
      --model ${OPENAI_MODEL:-openai/gpt-oss-20b}
      --dtype auto
      --max-model-len 70000
      --gpu-memory-utilization 0.95
      --enforce-eager
      --kv-cache-dtype fp8_e5m2
      --enable-prefix-caching
      --enable-chunked-prefill
      --max-num-seqs 4
      --enable-auto-tool-choice
      --tool-call-parser openai
    ports:
      - "8001:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
    ipc: host
    networks:
      - research-net
    restart: unless-stopped

networks:
  research-net:
    driver: bridge

volumes:
  db-data:
