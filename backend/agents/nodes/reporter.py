"""
Reporter node - generates the final research report.

Synthesizes all completed research steps into a comprehensive report.
Explicitly handles knowledge gaps from failed steps.
"""

import logging
from typing import Literal

from langchain_core.messages import AIMessage, SystemMessage
from langgraph.types import Command

from backend.agents.state import ResearchState
from backend.core.llm import get_llm

logger = logging.getLogger(__name__)

REPORTER_PROMPT = """You are the Reporter for a deep research system.

Your job is to create a comprehensive research report based on the completed research.

ORIGINAL RESEARCH QUERY:
{original_query}

COMPLETED RESEARCH FINDINGS (High Confidence):
{research_findings}

PARTIAL FINDINGS (Lower Confidence):
{partial_findings}

KNOWLEDGE GAPS:
{knowledge_gaps}

YOUR TASK:
Create a well-structured Markdown report that:
1. Directly addresses the original query
2. Synthesizes key findings from all research steps
3. Clearly distinguishes between confirmed findings and partial/uncertain information
4. Explicitly states what could NOT be found (knowledge gaps)
5. Uses proper Markdown formatting (headers, lists, etc.)
6. Cites sources where available

REPORT STRUCTURE:
# Research Report: [Topic]

## Executive Summary
[Brief overview of key findings + notable gaps]

## Detailed Findings
[Organized by theme, with confidence indicators where needed]

## Information Gaps
[What we tried but couldn't find - only if there are gaps]

## Key Insights
[Most important takeaways]

## Sources
[List of sources if available]

---
*Generated by damn-so-deep-research*

Write the report in the same language as the original query.
Be honest about limitations - partial information is better than pretending to have complete answers."""


def format_knowledge_gaps(failed_steps: list[dict]) -> str:
    """Format failed steps with their substeps into readable knowledge gaps."""
    if not failed_steps:
        return "None - all research steps completed successfully."

    gaps = []
    for step in failed_steps:
        gap_text = f"### {step['description']}\n"

        substeps = step.get("substeps", [])
        if substeps:
            gap_text += "**Attempts made:**\n"
            for substep in substeps:
                queries = substep.get("search_queries", [])
                queries_str = ", ".join(queries) if queries else "N/A"
                error = substep.get("error", "Unknown error")[:150]
                gap_text += f"- Attempt {substep['id'] + 1}: queries=[{queries_str}]\n"
                gap_text += f"  Result: {error}\n"
        else:
            gap_text += f"**Error:** {step.get('error', 'No details available')}\n"

        gaps.append(gap_text)

    return "\n".join(gaps)


def format_partial_findings(failed_steps: list[dict]) -> str:
    """Extract any partial findings from failed steps."""
    partial = []

    for step in failed_steps:
        accumulated = step.get("accumulated_findings", [])
        if accumulated:
            partial.append(f"### {step['description']} (Partial)")
            partial.append("*Note: This information was collected but may be incomplete.*\n")
            for finding in accumulated[:3]:  # Limit to first 3
                # Truncate long findings
                truncated = finding[:500] + "..." if len(finding) > 500 else finding
                partial.append(truncated)
            partial.append("")

    return "\n".join(partial) if partial else "None"


async def reporter_node(
    state: ResearchState,
) -> Command[Literal["__end__"]]:
    """
    Generates the final research report.

    Handles three categories of steps:
    - DONE: Reliable findings (high confidence)
    - FAILED with accumulated_findings: Partial information (lower confidence)
    - FAILED without findings: Knowledge gaps (explicitly stated)
    - SKIPPED: Not critical, noted as skipped
    """
    run_id = state["run_id"]
    plan = state["plan"]
    original_query = state["original_query"]

    logger.info(f"Reporter generating report for run {run_id}")

    # Categorize steps
    completed_findings = []
    failed_steps = []
    skipped_steps = []

    for step in plan:
        if step["status"] == "DONE" and step.get("result"):
            completed_findings.append(
                f"### {step['description']}\n{step['result']}"
            )
        elif step["status"] == "SKIPPED":
            skipped_steps.append(step)
            completed_findings.append(
                f"### {step['description']}\n*Skipped: {step.get('result', 'Not critical')}*"
            )
        elif step["status"] == "FAILED":
            failed_steps.append(step)

    # Check if this is a total failure case
    all_failed = all(s["status"] == "FAILED" for s in plan)

    if all_failed:
        logger.warning(f"Research completely failed: all {len(plan)} steps failed")

        # Build detailed failure report
        gap_details = format_knowledge_gaps(failed_steps)
        partial = format_partial_findings(failed_steps)

        report = f"""# Результаты исследования

К сожалению, не удалось найти достаточно информации по вашему запросу.

**Исходный запрос:** {original_query}

## Что было найдено

{partial if partial != "None" else "К сожалению, не удалось собрать полезную информацию."}

## Что не удалось найти

{gap_details}

## Рекомендации

- Попробуйте переформулировать запрос более конкретно
- Укажите дополнительный контекст или ключевые слова
- Разбейте сложный вопрос на несколько простых
- Проверьте, доступна ли эта информация в открытых источниках

---
*Generated by damn-so-deep-research*"""

    else:
        # Normal report with findings and gaps
        if not completed_findings:
            findings_text = "No completed research findings."
        else:
            findings_text = "\n\n".join(completed_findings)

        partial_findings_text = format_partial_findings(failed_steps)
        knowledge_gaps_text = format_knowledge_gaps(failed_steps)

        # Generate report via LLM
        llm = get_llm(temperature=0.3)
        messages = [
            SystemMessage(
                content=REPORTER_PROMPT.format(
                    original_query=original_query,
                    research_findings=findings_text,
                    partial_findings=partial_findings_text,
                    knowledge_gaps=knowledge_gaps_text,
                )
            ),
        ]

        response = await llm.ainvoke(messages)
        report = response.content

    logger.info(f"Report generated: {len(report)} characters")

    return Command(
        update={
            "phase": "done",
            "messages": [
                AIMessage(content=report, name="Reporter"),
            ],
        },
        goto="__end__",
    )
